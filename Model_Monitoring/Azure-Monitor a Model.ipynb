{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Monitor a Model\n",
        "\n",
        "When you've deployed a model into production as a service, you'll want to monitor it to track usage and explore the requests it processes. You can use Azure Application Insights to monitor activity for a model service endpoint."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace.\n",
        "\n",
        "> **Note**: If you haven't already established an authenticated session with your Azure subscription, you'll be prompted to authenticate by clicking a link, entering an authentication code, and signing into Azure."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to work with', ws.name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready to work with aml-DSTeam-RnD-001\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1683632022328
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare a model for deployment\n",
        "\n",
        "Now we need a model to deploy. Run the code below to:\n",
        "\n",
        "1. Create and register a dataset.\n",
        "2. Train a model using the dataset.\n",
        "3. Register the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from azureml.core import Dataset\n",
        "\n",
        "# Upload data files to the default datastore\n",
        "default_ds = ws.get_default_datastore()\n",
        "default_ds.upload_files(files=['data/diabetes.csv', 'diabetes2.csv'],\n",
        "                       target_path='diabetes-data/',\n",
        "                       overwrite=True,\n",
        "                       show_progress=True)\n",
        "                       \n",
        "#Create a tabular dataset from the path on the datastore\n",
        "print('Creating dataset...')\n",
        "data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "# Register the tabular dataset\n",
        "print('Registering dataset...')\n",
        "try:\n",
        "    data_set = data_set.register(workspace=ws, \n",
        "                               name='diabetes dataset',\n",
        "                               description='diabetes data',\n",
        "                               tags = {'format':'CSV'},\n",
        "                               create_new_version=True)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "\n",
        "# Create an Azure ML experiment in your workspace\n",
        "experiment = Experiment(workspace=ws, name='mslearn-train-diabetes')\n",
        "run = experiment.start_logging()\n",
        "print(\"Starting experiment:\", experiment.name)\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = data_set.to_pandas_dataframe()\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train a decision tree model\n",
        "print('Training a decision tree model')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Save the trained model\n",
        "model_file = 'diabetes_model.pkl'\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
        "\n",
        "# Complete the run\n",
        "run.complete()\n",
        "\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
        "                   tags={'Training context':'Inline Training'},\n",
        "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
        "\n",
        "# Get the registered model\n",
        "model = ws.models['diabetes_model']\n",
        "\n",
        "print('Model trained and registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"datastore.upload_files\" is deprecated after version 1.0.69. Please use \"FileDatasetFactory.upload_directory\" instead. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        },
        {
          "output_type": "error",
          "ename": "UserErrorException",
          "evalue": "UserErrorException:\n\tMessage: 'data/diabetes.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"'data/diabetes.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Upload data files to the default datastore\u001b[39;00m\n\u001b[1;32m     12\u001b[0m default_ds \u001b[38;5;241m=\u001b[39m ws\u001b[38;5;241m.\u001b[39mget_default_datastore()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mdefault_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/diabetes.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiabetes2.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiabetes-data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#Create a tabular dataset from the path on the datastore\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreating dataset...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_dataset_deprecation.py:26\u001b[0m, in \u001b[0;36mdeprecated.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     _warn_deprecation(target, replacement)  \u001b[38;5;66;03m# only raise warning for top-level invocation\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     _warning_silenced_for \u001b[38;5;241m=\u001b[39m target\n\u001b[0;32m---> 26\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _warning_silenced_for \u001b[38;5;241m==\u001b[39m target:\n\u001b[1;32m     28\u001b[0m     _warning_silenced_for \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/azure_storage_datastore.py:978\u001b[0m, in \u001b[0;36mAzureBlobDatastore.upload_files\u001b[0;34m(self, files, relative_root, target_path, overwrite, show_progress)\u001b[0m\n\u001b[1;32m    975\u001b[0m target_path \u001b[38;5;241m=\u001b[39m target_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    976\u001b[0m relative_root \u001b[38;5;241m=\u001b[39m relative_root \u001b[38;5;129;01mor\u001b[39;00m common_path(files)\n\u001b[1;32m    977\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_upload_task(\n\u001b[0;32m--> 978\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_upload_from_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[1;32m    979\u001b[0m     overwrite,\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m target_file_path: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_service\u001b[38;5;241m.\u001b[39mget_blob_client(\n\u001b[1;32m    981\u001b[0m         container\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_name,\n\u001b[1;32m    982\u001b[0m         blob\u001b[38;5;241m=\u001b[39mtarget_file_path\n\u001b[1;32m    983\u001b[0m     )\u001b[38;5;241m.\u001b[39mexists(),\n\u001b[1;32m    984\u001b[0m     show_progress,\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m target, source: \u001b[38;5;28;01mlambda\u001b[39;00m: [\n\u001b[1;32m    986\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblob_service\u001b[38;5;241m.\u001b[39mget_blob_client(\n\u001b[1;32m    987\u001b[0m             container\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_name,\n\u001b[1;32m    988\u001b[0m             blob\u001b[38;5;241m=\u001b[39mtarget\n\u001b[1;32m    989\u001b[0m         )\u001b[38;5;241m.\u001b[39mupload_blob(\n\u001b[1;32m    990\u001b[0m             f, blob_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlockBlob\u001b[39m\u001b[38;5;124m\"\u001b[39m, overwrite\u001b[38;5;241m=\u001b[39moverwrite\n\u001b[1;32m    991\u001b[0m         ), f\u001b[38;5;241m.\u001b[39mclose()) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mopen\u001b[39m(source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m    992\u001b[0m     ][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    993\u001b[0m )\n\u001b[1;32m    994\u001b[0m module_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished AzureBlobDatastore.upload with count=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(count))\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataReference(datastore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, path_on_datastore\u001b[38;5;241m=\u001b[39mtarget_path)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/azure_storage_datastore.py:293\u001b[0m, in \u001b[0;36mAbstractAzureStorageDatastore._get_upload_from_files\u001b[0;34m(self, file_paths, target_path, relative_root, skip_root_check)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(file_path):\n\u001b[1;32m    291\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not point to a file. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease upload the file to cloud first if running in a cloud notebook.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserErrorException(err_msg\u001b[38;5;241m.\u001b[39mformat(file_path))\n\u001b[1;32m    295\u001b[0m target_file_path \u001b[38;5;241m=\u001b[39m to_unix_path(file_path)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relative_root \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m# need to do this because Windows doesn't support relpath if the partition is different\u001b[39;00m\n",
            "\u001b[0;31mUserErrorException\u001b[0m: UserErrorException:\n\tMessage: 'data/diabetes.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"'data/diabetes.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1683632205705
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy a model as a web service\n",
        "\n",
        "Now you're ready to deploy the registered model as a web service.\n",
        "\n",
        "First, create a folder for the deployment configuration files"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create a folder for the deployment files\n",
        "deployment_folder = './diabetes_service'\n",
        "os.makedirs(deployment_folder, exist_ok=True)\n",
        "print(deployment_folder, 'folder created.')\n",
        "\n",
        "# Set path for scoring script\n",
        "script_file = 'score_diabetes.py'\n",
        "script_path = os.path.join(deployment_folder,script_file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "./diabetes_service folder created.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you need an entry script that the service will use to score new data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_path\n",
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    global model\n",
        "    # Get the path to the deployed model file and load it\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'diabetes_model.pkl')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "# Called when a request is received\n",
        "def run(raw_data):\n",
        "    # Get the input data as a numpy array\n",
        "    data = json.loads(raw_data)['data']\n",
        "    np_data = np.array(data)\n",
        "    # Get a prediction from the model\n",
        "    predictions = model.predict(np_data)\n",
        "    \n",
        "    # print the data and predictions (so they'll be logged!)\n",
        "    log_text = 'Data:' + str(data) + ' - Predictions:' + str(predictions)\n",
        "    print(log_text)\n",
        "    \n",
        "    # Get the corresponding classname for each prediction (0 or 1)\n",
        "    classnames = ['not-diabetic', 'diabetic']\n",
        "    predicted_classes = []\n",
        "    for prediction in predictions:\n",
        "        predicted_classes.append(classnames[prediction])\n",
        "    # Return the predictions as JSON\n",
        "    return json.dumps(predicted_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Writing ./diabetes_service/score_diabetes.py\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can deploy the service (in this case, as an Azure Container Instance (ACI).\n",
        "\n",
        "> **Note**: This can take a few minutes - wait until the state is shown as **Healthy**."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "\n",
        "# Configure the scoring environment\n",
        "aci_service_env = Environment(name='aci_service-env')\n",
        "python_packages = ['scikit-learn', 'azureml-defaults', 'azure-ml-api-sdk']\n",
        "for package in python_packages:\n",
        "    aci_service_env.python.conda_dependencies.add_pip_package(package)\n",
        "inference_config = InferenceConfig(source_directory=deployment_folder,\n",
        "                                   entry_script=script_file,\n",
        "                                   environment=aci_service_env)\n",
        "\n",
        "# Configure the web service container\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "# Deploy the model as a service\n",
        "print('Deploying model...')\n",
        "service_name = \"diabetes-service-app-insights\"\n",
        "aci_service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n",
        "aci_service.wait_for_deployment(show_output = True)\n",
        "print(aci_service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Deploying model...\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_24981/1448077430.py:20: FutureWarning: azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n  aci_service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-03-16 15:09:41+00:00 Creating Container Registry if not exists.\n2023-03-16 15:09:42+00:00 Building image..\n2023-03-16 15:20:00+00:00 Generating deployment configuration.\n2023-03-16 15:20:02+00:00 Submitting deployment to compute..\n2023-03-16 15:20:06+00:00 Checking the status of deployment diabetes-service-app-insights..\n2023-03-16 15:21:40+00:00 Checking the status of inference endpoint diabetes-service-app-insights.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nHealthy\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enable Application Insights\n",
        "\n",
        "Next, you need to enable Application Insights for the service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable AppInsights\n",
        "aci_service.update(enable_app_insights=True)\n",
        "print('AppInsights enabled!')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AppInsights enabled!\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the web service\n",
        "\n",
        "With the service deployed, now you can consume it from a client application.\n",
        "\n",
        "First, determine the URL to which these applications must submit their requests."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = aci_service.scoring_uri\n",
        "print(endpoint)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "http://226c44fe-e8ae-4d71-ad7d-e65220eedd80.eastus.azurecontainer.io/score\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you know the endpoint URI, an application can simply make an HTTP request, sending the patient data in JSON (or binary) format, and receive back the predicted class(es).\n",
        "\n",
        "> **Tip**: If an error occurs because the service endpoint isn't ready. Wait a few seconds and try again!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Create new data for inferencing\n",
        "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
        "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
        "\n",
        "# Convert the array to a serializable list in a JSON document\n",
        "input_json = json.dumps({\"data\": x_new})\n",
        "\n",
        "# Set the content type\n",
        "headers = { 'Content-Type':'application/json' }\n",
        "\n",
        "# Get the predictions\n",
        "predictions = requests.post(endpoint, input_json, headers = headers)\n",
        "print(predictions.status_code)\n",
        "if predictions.status_code == 200:\n",
        "    predicted_classes = json.loads(predictions.json())\n",
        "    for i in range(len(x_new)):\n",
        "        print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "200\nPatient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\nPatient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can view the data logged for the service endpoint:\n",
        "\n",
        "1. In the [Azure portal](https://portal.azure.com), open your Machine Learning workspace.\n",
        "2. On the **Overview** page, click the link for the associated **Application Insights** resource.\n",
        "3. On the Application Insights blade, click **Logs**. \n",
        "\n",
        "    > **Note**: If this is the first time you've opened log analytics, you may need to click **Get Started** to open the query editor. If a tip explaining how to write a query is displayed, close it.\n",
        "\n",
        "4. Paste the following query into the query editor and click **Run**\n",
        "    ```\n",
        "    traces\n",
        "    |where  message == \"STDOUT\"\n",
        "      and customDimensions.[\"Service Name\"] == \"diabetes-service-app-insights\"\n",
        "    |project timestamp, customDimensions.Content\n",
        "    ```\n",
        "5. View the results. At first there may be none, because an ACI web service can take as long as five minutes to send the telemetry to Application Insights. Wait a few minutes and re-run the query until you see the logged data and predictions.\n",
        "6. When you've reviewed the logged data, close the Application Insights query page."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete the service\n",
        "\n",
        "When you no longer need your service, you should delete it.\n",
        "\n",
        "> **Note**: If the service is in use, you may not be able to delete it immediately."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    aci_service.delete()\n",
        "    print('Service deleted.')\n",
        "except Exception as ex:\n",
        "    print(ex.message)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more information about using Application Insights to monitor a deployed service, see the [Azure Machine Learning documentation](https://docs.microsoft.com/azure/machine-learning/how-to-enable-app-insights)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}